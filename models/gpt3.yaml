model: gpt3
params:
    max_tokens: 2000,
    temperature: 0.8
    stream: True